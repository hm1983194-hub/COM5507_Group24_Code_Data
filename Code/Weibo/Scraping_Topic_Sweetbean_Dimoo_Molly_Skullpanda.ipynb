{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7006dd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "############# 小甜豆 ##############\n",
    "import requests\n",
    "\n",
    "headers = {\n",
    "    \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36\",\n",
    "    \"referer\": \"https://popmart.world.tmall.com/search.htm?spm=a312a.7700824.w4011-15691211895.234.186c5e60uMuZmF&search=y&scene=taobao_shop&orderType=hotsell_desc&viewType=list&pageNo=5&tsearch=y\",\n",
    "    \"cookie\": \"SCF=ApFxOmZR_xsG7Zo91J4ByU7i4IE1sHMFEGNUQRypPgosKbbk66rpjkMbuf-925bBKf_VPkZsMAfxGOHS4F9s__k.; SINAGLOBAL=2000975961750.401.1761899716082; ALF=1766456142; SUB=_2A25EJh4eDeRhGeNM6VsR9ynFyD2IHXVnWh_WrDV8PUJbkNANLUPekW1NTiXseZHXj4yEhaL47eIuxPtbK6hZYR7A; SUBP=0033WrSXqPxfM725Ws9jqgMF55529P9D9WhKSsXoBkEgeh2zwP.845hz5JpX5KMhUgL.Fo-Eeo.7S0M4e022dJLoIEnLxKqLBKnLBo2LxKnL122LBo2LxKqL1KnL1KeLxK-L1hqLBoMEe0e0; _s_tentry=-; Apache=738412649430.4799.1763864143978; ULV=1763864143980:2:1:1:738412649430.4799.1763864143978:1761899716083\"\n",
    "}\n",
    "\n",
    "url = \"https://s.weibo.com/weibo?q=%23小甜豆%23\"\n",
    "\n",
    "response = requests.get(url=url, headers=headers)\n",
    "if response.status_code == 200:\n",
    "    print(\"success\")\n",
    "else:\n",
    "    print(\"failed...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45161ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /opt/anaconda3/lib/python3.13/site-packages (4.36.0)\n",
      "Requirement already satisfied: urllib3<3.0,>=2.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
      "Requirement already satisfied: trio<1.0,>=0.30.0 in /opt/anaconda3/lib/python3.13/site-packages (from selenium) (0.31.0)\n",
      "Requirement already satisfied: trio-websocket<1.0,>=0.12.2 in /opt/anaconda3/lib/python3.13/site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2025.6.15 in /opt/anaconda3/lib/python3.13/site-packages (from selenium) (2025.8.3)\n",
      "Requirement already satisfied: typing_extensions<5.0,>=4.14.0 in /opt/anaconda3/lib/python3.13/site-packages (from selenium) (4.15.0)\n",
      "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in /opt/anaconda3/lib/python3.13/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from trio<1.0,>=0.30.0->selenium) (24.3.0)\n",
      "Requirement already satisfied: sortedcontainers in /opt/anaconda3/lib/python3.13/site-packages (from trio<1.0,>=0.30.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.13/site-packages (from trio<1.0,>=0.30.0->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in /opt/anaconda3/lib/python3.13/site-packages (from trio<1.0,>=0.30.0->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from trio<1.0,>=0.30.0->selenium) (1.3.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /opt/anaconda3/lib/python3.13/site-packages (from trio-websocket<1.0,>=0.12.2->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /opt/anaconda3/lib/python3.13/site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /opt/anaconda3/lib/python3.13/site-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n",
      "Requirement already satisfied: webdriver-manager in /opt/anaconda3/lib/python3.13/site-packages (4.0.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.13/site-packages (from webdriver-manager) (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in /opt/anaconda3/lib/python3.13/site-packages (from webdriver-manager) (1.1.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.13/site-packages (from webdriver-manager) (24.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests->webdriver-manager) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from requests->webdriver-manager) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests->webdriver-manager) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests->webdriver-manager) (2025.8.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "!pip install webdriver-manager  # 这个库可以自动管理浏览器驱动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f26f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在启动浏览器...\n",
      "正在设置 Cookie...\n",
      "\n",
      "============================================================\n",
      "【稳健登录指南】\n",
      "1. 如果页面正常显示：直接按回车。\n",
      "2. 如果显示登录框：\n",
      "   A. 【推荐】使用微博APP扫码登录 (扫码最稳定，不会闪退)\n",
      "   B. 如果必须用短信验证码，现在的代码已加强防闪退，可以尝试。\n",
      "============================================================\n",
      "\n",
      "\n",
      "===== 正在爬取第 1 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 23 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 2 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 9 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 3 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 9 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 4 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 9 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 5 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 9 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 6 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 8 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 7 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 10 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 8 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 10 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 9 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 9 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 10 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 9 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 11 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 8 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 12 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 8 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 13 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 6 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 14 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 8 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 15 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 10 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 16 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 9 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 17 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 10 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 18 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 9 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 19 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 10 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 20 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 10 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 21 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 8 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 22 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 8 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 23 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 8 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 24 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 8 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 25 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 10 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 26 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 8 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 27 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 10 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 28 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 8 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 29 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 9 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 30 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 10 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 31 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 9 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 32 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 9 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 33 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 10 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 34 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 10 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 35 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 10 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 36 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 10 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 37 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 7 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 38 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 9 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 39 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 6 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 40 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 6 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 41 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 6 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 42 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 9 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 43 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 6 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 44 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 5 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 45 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 7 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 46 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 4 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 47 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 9 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 48 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 4 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 49 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 9 条数据。\n",
      "   >> 准备翻页...\n",
      "\n",
      "===== 正在爬取第 50 页 =====\n",
      "   >> 正在解析数据...\n",
      "   >> 已保存 9 条数据。\n",
      "\n",
      ">>> 已完成 50 页任务，程序结束。 <<<\n",
      "任务结束。\n"
     ]
    }
   ],
   "source": [
    "############# 小甜豆 ##############\n",
    "import time\n",
    "import csv\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# --- 1. 配置区 ---\n",
    "\n",
    "MY_COOKIE = \"SCF=ApFxOmZR_xsG7Zo91J4ByU7i4IE1sHMFEGNUQRypPgosKbbk66rpjkMbuf-925bBKf_VPkZsMAfxGOHS4F9s__k.; SINAGLOBAL=2000975961750.401.1761899716082; ALF=1766456142; SUB=_2A25EJh4eDeRhGeNM6VsR9ynFyD2IHXVnWh_WrDV8PUJbkNANLUPekW1NTiXseZHXj4yEhaL47eIuxPtbK6hZYR7A; SUBP=0033WrSXqPxfM725Ws9jqgMF55529P9D9WhKSsXoBkEgeh2zwP.845hz5JpX5KMhUgL.Fo-Eeo.7S0M4e022dJLoIEnLxKqLBKnLBo2LxKnL122LBo2LxKqL1KnL1KeLxK-L1hqLBoMEe0e0; _s_tentry=-; Apache=738412649430.4799.1763864143978; ULV=1763864143980:2:1:1:738412649430.4799.1763864143978:1761899716083\"\n",
    "URL = \"https://s.weibo.com/weibo?q=%23小甜豆%23\"\n",
    "CSV_FILE = 'weibo_xiaotiandou_finish.csv'\n",
    "MAX_PAGE = 50\n",
    "DEFAULT_YEAR = \"2025\"\n",
    "\n",
    "# --- 2. 核心处理函数 ---\n",
    "\n",
    "def parse_cookies(cookie_str):\n",
    "    cookies_dict = []\n",
    "    for item in cookie_str.split(';'):\n",
    "        item = item.strip()\n",
    "        if not item or '=' not in item:\n",
    "            continue\n",
    "        try:\n",
    "            name, value = item.split('=', 1)\n",
    "            cookies_dict.append({'name': name, 'value': value, 'domain': '.weibo.com'})\n",
    "        except:\n",
    "            pass\n",
    "    return cookies_dict\n",
    "\n",
    "def extract_number(text):\n",
    "    match = re.search(r'\\d+', text)\n",
    "    return int(match.group(0)) if match else 0\n",
    "\n",
    "def process_time_regex(raw_text):\n",
    "    if not raw_text: return \"\", \"\", \"\"\n",
    "    text = re.sub(r'\\s+', ' ', raw_text).strip()\n",
    "    now = datetime.datetime.now()\n",
    "\n",
    "    match_full = re.search(r'(\\d{4})年(\\d{1,2})月(\\d{1,2})日\\s*(\\d{1,2}:\\d{2})', text)\n",
    "    if match_full: return match_full.group(1), f\"{match_full.group(2)}月{match_full.group(3)}日\", match_full.group(4)\n",
    "\n",
    "    match_no_year = re.search(r'(\\d{1,2})月(\\d{1,2})日\\s*(\\d{1,2}:\\d{2})', text)\n",
    "    if match_no_year: return DEFAULT_YEAR, f\"{match_no_year.group(1)}月{match_no_year.group(2)}日\", match_no_year.group(3)\n",
    "\n",
    "    match_today = re.search(r'今天\\s*(\\d{1,2}:\\d{2})', text)\n",
    "    if match_today: return str(now.year), f\"{now.month}月{now.day}日\", match_today.group(1)\n",
    "\n",
    "    if \"分\" in text or \"秒\" in text or \"刚刚\" in text: return str(now.year), f\"{now.month}月{now.day}日\", now.strftime(\"%H:%M\")\n",
    "\n",
    "    match_date_only = re.search(r'(\\d{1,2})月(\\d{1,2})日', text)\n",
    "    if match_date_only: return DEFAULT_YEAR, f\"{match_date_only.group(1)}月{match_date_only.group(2)}日\", \"00:00\"\n",
    "\n",
    "    return \"\", text, \"\" \n",
    "\n",
    "def simulate_human_scroll(driver):\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    current_position = 0\n",
    "    while current_position < last_height:\n",
    "        step = random.randint(500, 800)\n",
    "        current_position += step\n",
    "        driver.execute_script(f\"window.scrollTo(0, {current_position});\")\n",
    "        time.sleep(random.uniform(0.3, 0.6))\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if current_position > new_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(1)\n",
    "\n",
    "def save_to_csv(data, filename):\n",
    "    file_exists = os.path.isfile(filename)\n",
    "    try:\n",
    "        with open(filename, 'a', newline='', encoding='utf-8-sig') as f:\n",
    "            fieldnames = ['用户名', '帖子内容', '发布年份', '发布日期', '发布时间', '转发数', '评论数', '点赞数']\n",
    "            writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "            if not file_exists:\n",
    "                writer.writeheader()\n",
    "            writer.writerows(data)\n",
    "    except Exception as e:\n",
    "        print(f\"写入CSV失败: {e}\")\n",
    "\n",
    "# --- 3. 主程序 ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--start-maximized\")\n",
    "    \n",
    "    # 【超级隐身设置 1】禁用自动化标志\n",
    "    chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    # 【超级隐身设置 2】排除自动化开关\n",
    "    chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "    # 【调试设置】脚本结束时不自动关闭浏览器（防止闪退后看不到原因）\n",
    "    chrome_options.add_experimental_option(\"detach\", True)\n",
    "\n",
    "    chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36\")\n",
    "\n",
    "    print(\"正在启动浏览器...\")\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "    # 【超级隐身设置 3】在页面加载前执行 CDP 命令，修改 navigator.webdriver 为 undefined\n",
    "    # 这是解决登录闪退、验证码拦截的最关键一步\n",
    "    driver.execute_cdp_cmd(\"Page.addScriptToEvaluateOnNewDocument\", {\n",
    "        \"source\": \"\"\"\n",
    "        Object.defineProperty(navigator, 'webdriver', {\n",
    "            get: () => undefined\n",
    "        })\n",
    "        \"\"\"\n",
    "    })\n",
    "\n",
    "    try:\n",
    "        driver.get(\"https://weibo.com/\")\n",
    "        time.sleep(3)\n",
    "\n",
    "        print(\"正在设置 Cookie...\")\n",
    "        cookies = parse_cookies(MY_COOKIE)\n",
    "        for cookie in cookies:\n",
    "            try:\n",
    "                driver.add_cookie(cookie)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        driver.get(URL)\n",
    "        time.sleep(3)\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"【稳健登录指南】\")\n",
    "        print(\"1. 如果页面正常显示：直接按回车。\")\n",
    "        print(\"2. 如果显示登录框：\")\n",
    "        print(\"   A. 【推荐】使用微博APP扫码登录 (扫码最稳定，不会闪退)\")\n",
    "        print(\"   B. 如果必须用短信验证码，现在的代码已加强防闪退，可以尝试。\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "        input(\"登录完成并准备好后，请按 Enter 键继续...\")\n",
    "\n",
    "        page_count = 1\n",
    "        \n",
    "        while True:\n",
    "            print(f\"\\n===== 正在爬取第 {page_count} 页 =====\")\n",
    "            \n",
    "            try:\n",
    "                WebDriverWait(driver, 20).until(\n",
    "                    EC.presence_of_element_located((By.CSS_SELECTOR, \"div.card-wrap\"))\n",
    "                )\n",
    "            except TimeoutException:\n",
    "                print(\"页面加载超时。\")\n",
    "                break\n",
    "\n",
    "            simulate_human_scroll(driver)\n",
    "\n",
    "            try:\n",
    "                expand_buttons = driver.find_elements(By.XPATH, '//a[@action-type=\"fl_unfold\"]')\n",
    "                for btn in expand_buttons:\n",
    "                    try:\n",
    "                        driver.execute_script(\"arguments[0].click();\", btn)\n",
    "                        time.sleep(0.5)\n",
    "                    except:\n",
    "                        pass\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            print(\"   >> 正在解析数据...\")\n",
    "            page_data = []\n",
    "            posts = driver.find_elements(By.CSS_SELECTOR, \"div.card-wrap\")\n",
    "            \n",
    "            for post in posts:\n",
    "                try:\n",
    "                    try:\n",
    "                        user_name = post.find_element(By.CSS_SELECTOR, 'p.txt').get_attribute('nick-name')\n",
    "                        if not user_name: continue\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "                    content = \"\"\n",
    "                    try:\n",
    "                        content_element = post.find_element(By.CSS_SELECTOR, 'p[node-type=\"feed_list_content\"]')\n",
    "                        content = content_element.get_attribute('textContent').replace('收起', '').replace('展开', '').strip()\n",
    "                    except:\n",
    "                        pass\n",
    "                    if not content: content = \"[仅图片/表情或提取失败]\"\n",
    "\n",
    "                    year, date_part, time_part = \"\", \"\", \"\"\n",
    "                    try:\n",
    "                        # 优先使用 wb_time 定位\n",
    "                        time_element = post.find_element(By.CSS_SELECTOR, 'a[suda-data*=\"click:wb_time\"]')\n",
    "                        raw_time_text = time_element.get_attribute('textContent')\n",
    "                        year, date_part, time_part = process_time_regex(raw_time_text)\n",
    "                    except Exception:\n",
    "                        # 兜底方案：遍历所有链接\n",
    "                        try:\n",
    "                            links = post.find_element(By.CSS_SELECTOR, 'p.from').find_elements(By.TAG_NAME, 'a')\n",
    "                            for link in links:\n",
    "                                t = link.get_attribute('textContent')\n",
    "                                if \"月\" in t or \"今天\" in t or \"分\" in t:\n",
    "                                    year, date_part, time_part = process_time_regex(t)\n",
    "                                    break\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "                    forwards = comments = likes = 0\n",
    "                    try:\n",
    "                        acts = post.find_elements(By.CSS_SELECTOR, 'div.card-act > ul > li')\n",
    "                        if len(acts) >= 3:\n",
    "                            forwards = extract_number(acts[0].text)\n",
    "                            comments = extract_number(acts[1].text)\n",
    "                            likes = extract_number(acts[2].text)\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    page_data.append({\n",
    "                        '用户名': user_name, \n",
    "                        '帖子内容': content, \n",
    "                        '发布年份': year,\n",
    "                        '发布日期': date_part,\n",
    "                        '发布时间': time_part,\n",
    "                        '转发数': forwards, \n",
    "                        '评论数': comments, \n",
    "                        '点赞数': likes\n",
    "                    })\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            if page_data:\n",
    "                save_to_csv(page_data, CSV_FILE)\n",
    "                print(f\"   >> 已保存 {len(page_data)} 条数据。\")\n",
    "            else:\n",
    "                print(\"   >> 本页未提取到数据。\")\n",
    "\n",
    "            if page_count >= MAX_PAGE:\n",
    "                print(f\"\\n>>> 已完成 {MAX_PAGE} 页任务，程序结束。 <<<\")\n",
    "                break\n",
    "\n",
    "            try:\n",
    "                next_btn = driver.find_element(By.CSS_SELECTOR, 'a.next')\n",
    "                print(\"   >> 准备翻页...\")\n",
    "                time.sleep(random.uniform(3, 5))\n",
    "                next_btn.click()\n",
    "                page_count += 1\n",
    "                time.sleep(random.uniform(3, 5))\n",
    "            except NoSuchElementException:\n",
    "                print(\"没有下一页了。\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"翻页出错: {e}\")\n",
    "                break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"程序出错: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        # driver.quit() # 注释掉这一行，让浏览器在出错后保持打开状态，方便你检查\n",
    "        print(\"任务结束。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d114b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在启动续爬模式 (目标: 2025-06-01 ~ 2025-09-21)...\n",
      "\n",
      "============================================================\n",
      "【请手动扫码登录】\n",
      "登录成功看到首页后，回到这里按 Enter 键。\n",
      "============================================================\n",
      "\n",
      "正在热身...\n",
      "任务计划：剩余 4 个时间段。\n",
      "\n",
      ">>> 正在抓取: 2025-09-01 至 2025-09-21 <<<\n",
      "   第 1 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 2 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 3 页... -> 保存 8 条 (去重 0 条)\n",
      "   第 4 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 5 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 6 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 7 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 8 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 9 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 10 页... -> 保存 9 条 (去重 0 条)\n",
      "   第 11 页... -> 保存 1 条 (去重 0 条)\n",
      "   无下一页。\n",
      "\n",
      ">>> 正在抓取: 2025-08-01 至 2025-08-31 <<<\n",
      "   第 1 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 2 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 3 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 4 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 5 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 6 页... -> 保存 9 条 (去重 0 条)\n",
      "   第 7 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 8 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 9 页... -> 保存 9 条 (去重 0 条)\n",
      "   第 10 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 11 页... -> 保存 9 条 (去重 0 条)\n",
      "   第 12 页... -> 保存 9 条 (去重 0 条)\n",
      "   第 13 页... -> 保存 8 条 (去重 0 条)\n",
      "   第 14 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 15 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 16 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 17 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 18 页... -> 保存 1 条 (去重 0 条)\n",
      "   无下一页。\n",
      "\n",
      ">>> 正在抓取: 2025-07-01 至 2025-07-31 <<<\n",
      "   第 1 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 2 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 3 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 4 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 5 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 6 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 7 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 8 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 9 页... -> 保存 8 条 (去重 0 条)\n",
      "   第 10 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 11 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 12 页... -> 保存 9 条 (去重 0 条)\n",
      "   第 13 页... -> 保存 8 条 (去重 0 条)\n",
      "   第 14 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 15 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 16 页... -> 保存 9 条 (去重 0 条)\n",
      "   第 17 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 18 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 19 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 20 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 21 页... -> 保存 9 条 (去重 0 条)\n",
      "   无下一页。\n",
      "\n",
      ">>> 正在抓取: 2025-06-01 至 2025-06-30 <<<\n",
      "   第 1 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 2 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 3 页... -> 保存 9 条 (去重 0 条)\n",
      "   第 4 页... -> 保存 9 条 (去重 0 条)\n",
      "   第 5 页... -> 保存 9 条 (去重 0 条)\n",
      "   第 6 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 7 页... -> 保存 9 条 (去重 0 条)\n",
      "   第 8 页... -> 保存 9 条 (去重 0 条)\n",
      "   第 9 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 10 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 11 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 12 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 13 页... -> 保存 9 条 (去重 0 条)\n",
      "   第 14 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 15 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 16 页... -> 保存 10 条 (去重 0 条)\n",
      "   无下一页。\n"
     ]
    }
   ],
   "source": [
    "############# Dimoo（去重爬取版） ##########\n",
    "import time\n",
    "import csv\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import datetime\n",
    "import urllib.parse\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# --- 1. 配置区 ---\n",
    "\n",
    "RAW_KEYWORD = \"#DIMOO#\"\n",
    "CSV_FILE = 'weibo_Dimoo_Future_2025.csv' # 保持文件名一致，自动追加\n",
    "\n",
    "# 【精准定位续爬】\n",
    "# 脚本是倒序运行的，所以结束时间设为你的断点日期\n",
    "START_DATE = \"2025-07-01\"\n",
    "END_DATE = \"2025-09-21\" \n",
    "\n",
    "MAX_PAGE_PER_MONTH = 50\n",
    "DEFAULT_YEAR = \"2025\"\n",
    "\n",
    "# --- 2. 核心工具函数 ---\n",
    "\n",
    "def get_date_ranges(start, end):\n",
    "    \"\"\"生成按月切分的时间段\"\"\"\n",
    "    start_date = datetime.datetime.strptime(start, \"%Y-%m-%d\")\n",
    "    end_date = datetime.datetime.strptime(end, \"%Y-%m-%d\")\n",
    "    ranges = []\n",
    "    current = start_date\n",
    "    while current <= end_date:\n",
    "        if current.month == 12:\n",
    "            next_month = current.replace(year=current.year+1, month=1, day=1)\n",
    "        else:\n",
    "            next_month = current.replace(month=current.month+1, day=1)\n",
    "        month_end = next_month - datetime.timedelta(days=1)\n",
    "        \n",
    "        # 修正最后一个月的时间边界 (这里会把9月修正为9月21日结束)\n",
    "        if month_end > end_date: \n",
    "            month_end = end_date\n",
    "            \n",
    "        if current <= month_end:\n",
    "            ranges.append((current.strftime(\"%Y-%m-%d\"), month_end.strftime(\"%Y-%m-%d\")))\n",
    "        current = next_month\n",
    "    \n",
    "    # 倒序：从 9月 -> 8月 -> 7月 -> 6月\n",
    "    return ranges[::-1] \n",
    "\n",
    "def extract_number(text):\n",
    "    match = re.search(r'\\d+', text)\n",
    "    return int(match.group(0)) if match else 0\n",
    "\n",
    "def process_time_regex(raw_text):\n",
    "    if not raw_text: return \"\", \"\", \"\"\n",
    "    text = re.sub(r'\\s+', ' ', raw_text).strip()\n",
    "    now = datetime.datetime.now()\n",
    "    match_full = re.search(r'(\\d{4})年(\\d{1,2})月(\\d{1,2})日\\s*(\\d{1,2}:\\d{2})', text)\n",
    "    if match_full: return match_full.group(1), f\"{match_full.group(2)}月{match_full.group(3)}日\", match_full.group(4)\n",
    "    match_no_year = re.search(r'(\\d{1,2})月(\\d{1,2})日\\s*(\\d{1,2}:\\d{2})', text)\n",
    "    if match_no_year: return DEFAULT_YEAR, f\"{match_no_year.group(1)}月{match_no_year.group(2)}日\", match_no_year.group(3)\n",
    "    match_today = re.search(r'今天\\s*(\\d{1,2}:\\d{2})', text)\n",
    "    if match_today: return str(now.year), f\"{now.month}月{now.day}日\", match_today.group(1)\n",
    "    if \"分\" in text or \"秒\" in text or \"刚刚\" in text: return str(now.year), f\"{now.month}月{now.day}日\", now.strftime(\"%H:%M\")\n",
    "    match_date_only = re.search(r'(\\d{1,2})月(\\d{1,2})日', text)\n",
    "    if match_date_only: return DEFAULT_YEAR, f\"{match_date_only.group(1)}月{match_date_only.group(2)}日\", \"00:00\"\n",
    "    return \"\", text, \"\" \n",
    "\n",
    "def simulate_human_scroll(driver):\n",
    "    try:\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        current_position = 0\n",
    "        while current_position < last_height:\n",
    "            step = random.randint(600, 900)\n",
    "            current_position += step\n",
    "            driver.execute_script(f\"window.scrollTo(0, {current_position});\")\n",
    "            time.sleep(random.uniform(0.2, 0.5))\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if current_position > new_height: break\n",
    "            last_height = new_height\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(1.0)\n",
    "    except: pass\n",
    "\n",
    "def save_to_csv(data, filename):\n",
    "    file_exists = os.path.isfile(filename)\n",
    "    try:\n",
    "        with open(filename, 'a', newline='', encoding='utf-8-sig') as f:\n",
    "            fieldnames = ['用户名', '帖子内容', '发布年份', '发布日期', '发布时间', '转发数', '评论数', '点赞数', '抓取时段']\n",
    "            writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "            if not file_exists: writer.writeheader()\n",
    "            writer.writerows(data)\n",
    "    except Exception as e:\n",
    "        print(f\"写入CSV失败: {e}\")\n",
    "\n",
    "# --- 3. 浏览器配置 ---\n",
    "\n",
    "def get_stealth_driver():\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--start-maximized\")\n",
    "    chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "    chrome_options.add_experimental_option(\"detach\", True)\n",
    "    chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\")\n",
    "\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    \n",
    "    # 设置超时防断连\n",
    "    driver.set_page_load_timeout(120)\n",
    "    driver.set_script_timeout(120)\n",
    "\n",
    "    driver.execute_cdp_cmd(\"Page.addScriptToEvaluateOnNewDocument\", {\n",
    "        \"source\": \"\"\"\n",
    "            Object.defineProperty(navigator, 'webdriver', { get: () => undefined });\n",
    "            Object.defineProperty(navigator, 'plugins', { get: () => [1, 2, 3, 4, 5] });\n",
    "            Object.defineProperty(navigator, 'languages', { get: () => ['zh-CN', 'zh', 'en'] });\n",
    "        \"\"\"\n",
    "    })\n",
    "    return driver\n",
    "\n",
    "# --- 4. 主程序 ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(f\"正在启动续爬模式 (目标: {START_DATE} ~ {END_DATE})...\")\n",
    "    \n",
    "    try:\n",
    "        driver = get_stealth_driver()\n",
    "    except Exception as e:\n",
    "        print(\"\\n启动失败，请升级Selenium\")\n",
    "        exit()\n",
    "\n",
    "    seen_posts = set()\n",
    "\n",
    "    try:\n",
    "        # --- A. 登录 ---\n",
    "        driver.get(\"https://weibo.com/\")\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"【请手动扫码登录】\")\n",
    "        print(\"登录成功看到首页后，回到这里按 Enter 键。\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "        input(\"准备好后，请按 Enter 键...\")\n",
    "\n",
    "        # --- B. 热身 ---\n",
    "        print(\"正在热身...\")\n",
    "        encoded_keyword = urllib.parse.quote(RAW_KEYWORD)\n",
    "        try:\n",
    "            driver.get(f\"https://s.weibo.com/weibo?q={encoded_keyword}&Refer=index\")\n",
    "            simulate_human_scroll(driver)\n",
    "            time.sleep(random.uniform(2, 4))\n",
    "        except TimeoutException:\n",
    "            print(\"热身超时，跳过...\")\n",
    "\n",
    "        # --- C. 续爬开始 ---\n",
    "        date_ranges = get_date_ranges(START_DATE, END_DATE)\n",
    "        print(f\"任务计划：剩余 {len(date_ranges)} 个时间段。\")\n",
    "\n",
    "        for start_t, end_t in date_ranges:\n",
    "            search_url = f\"https://s.weibo.com/weibo?q={encoded_keyword}&typeall=1&suball=1&timescope=custom:{start_t}:{end_t}&Refer=g\"\n",
    "            \n",
    "            print(f\"\\n>>> 正在抓取: {start_t} 至 {end_t} <<<\")\n",
    "            try:\n",
    "                driver.get(search_url)\n",
    "                time.sleep(random.uniform(3, 5)) \n",
    "            except TimeoutException:\n",
    "                print(\"   加载超时，刷新...\")\n",
    "                driver.refresh()\n",
    "                time.sleep(5)\n",
    "\n",
    "            if \"抱歉，未找到\" in driver.page_source:\n",
    "                print(f\"   无内容，跳过。\")\n",
    "                continue\n",
    "\n",
    "            page_count = 1\n",
    "            while True:\n",
    "                print(f\"   第 {page_count} 页...\", end=\"\")\n",
    "                \n",
    "                try:\n",
    "                    WebDriverWait(driver, 15).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div.card-wrap\")))\n",
    "                except:\n",
    "                    print(\" -> 等待超时\")\n",
    "\n",
    "                simulate_human_scroll(driver)\n",
    "\n",
    "                try:\n",
    "                    expand_buttons = driver.find_elements(By.XPATH, '//a[@action-type=\"fl_unfold\"]')\n",
    "                    for btn in expand_buttons:\n",
    "                        driver.execute_script(\"arguments[0].click();\", btn)\n",
    "                        time.sleep(0.1)\n",
    "                except: pass\n",
    "\n",
    "                page_data = []\n",
    "                posts = driver.find_elements(By.CSS_SELECTOR, \"div.card-wrap\")\n",
    "                duplicate_count = 0\n",
    "                \n",
    "                for post in posts:\n",
    "                    try:\n",
    "                        if \"card-no-result\" in post.get_attribute(\"class\"): continue\n",
    "                        try:\n",
    "                            user_name = post.find_element(By.CSS_SELECTOR, 'p.txt').get_attribute('nick-name')\n",
    "                        except: continue\n",
    "                        \n",
    "                        content = \"\"\n",
    "                        try:\n",
    "                            content = post.find_element(By.CSS_SELECTOR, 'p[node-type=\"feed_list_content\"]').get_attribute('textContent').replace('收起', '').replace('展开', '').strip()\n",
    "                        except: pass\n",
    "                        if not content: content = \"[内容提取失败]\"\n",
    "\n",
    "                        year, date_part, time_part = \"\", \"\", \"\"\n",
    "                        try:\n",
    "                            time_element = post.find_element(By.CSS_SELECTOR, 'a[suda-data*=\"click:wb_time\"]')\n",
    "                            year, date_part, time_part = process_time_regex(time_element.get_attribute('textContent'))\n",
    "                        except:\n",
    "                            try:\n",
    "                                links = post.find_element(By.CSS_SELECTOR, 'p.from').find_elements(By.TAG_NAME, 'a')\n",
    "                                for link in links:\n",
    "                                    if \"月\" in link.text or \"今天\" in link.text:\n",
    "                                        year, date_part, time_part = process_time_regex(link.text)\n",
    "                                        break\n",
    "                            except: pass\n",
    "\n",
    "                        # 去重\n",
    "                        unique_id = f\"{user_name}_{content[:30]}_{date_part}_{time_part}\"\n",
    "                        if unique_id in seen_posts:\n",
    "                            duplicate_count += 1\n",
    "                            continue \n",
    "                        seen_posts.add(unique_id)\n",
    "\n",
    "                        forwards = comments = likes = 0\n",
    "                        try:\n",
    "                            acts = post.find_elements(By.CSS_SELECTOR, 'div.card-act > ul > li')\n",
    "                            if len(acts) >= 3:\n",
    "                                forwards = extract_number(acts[0].text)\n",
    "                                comments = extract_number(acts[1].text)\n",
    "                                likes = extract_number(acts[2].text)\n",
    "                        except: pass\n",
    "\n",
    "                        page_data.append({\n",
    "                            '用户名': user_name, '帖子内容': content, \n",
    "                            '发布年份': year, '发布日期': date_part, '发布时间': time_part,\n",
    "                            '转发数': forwards, '评论数': comments, '点赞数': likes,\n",
    "                            '抓取时段': f\"{start_t}_{end_t}\"\n",
    "                        })\n",
    "                    except: continue\n",
    "\n",
    "                if page_data:\n",
    "                    save_to_csv(page_data, CSV_FILE)\n",
    "                    print(f\" -> 保存 {len(page_data)} 条 (去重 {duplicate_count} 条)\")\n",
    "                else:\n",
    "                    print(f\" -> 本页无新数据 (可能已存过)\")\n",
    "\n",
    "                if page_count >= MAX_PAGE_PER_MONTH:\n",
    "                    print(\"   月度上限，下个月。\")\n",
    "                    break\n",
    "\n",
    "                try:\n",
    "                    next_btn = driver.find_element(By.CSS_SELECTOR, 'a.next')\n",
    "                    time.sleep(random.uniform(3, 5))\n",
    "                    next_btn.click()\n",
    "                    page_count += 1\n",
    "                    time.sleep(random.uniform(3, 5))\n",
    "                except:\n",
    "                    print(\"   无下一页。\")\n",
    "                    break\n",
    "            \n",
    "            time.sleep(random.uniform(3, 5))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"程序异常: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bdece0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在启动 (目标: 2025-07-01 ~ 2025-11-26)...\n",
      "\n",
      "============================================================\n",
      "【请手动扫码登录】\n",
      "登录成功看到首页后，回到这里按 Enter 键。\n",
      "============================================================\n",
      "\n",
      "已跳过热身，直接开始...\n",
      "任务计划：5 个时段。\n",
      "\n",
      ">>> 正在抓取: 2025-11-01 至 2025-11-26 <<<\n",
      "   第 1 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 2 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 3 页... -> 保存 6 条 (去重 0 条)\n",
      "   无下一页。\n",
      "\n",
      ">>> 正在抓取: 2025-10-01 至 2025-10-31 <<<\n",
      "   第 1 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 2 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 3 页... -> 保存 9 条 (去重 1 条)\n",
      "   第 4 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 5 页... -> 保存 9 条 (去重 0 条)\n",
      "   无下一页。\n",
      "\n",
      ">>> 正在抓取: 2025-09-01 至 2025-09-30 <<<\n",
      "   第 1 页... -> 保存 9 条 (去重 0 条)\n",
      "   第 2 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 3 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 4 页... -> 保存 9 条 (去重 0 条)\n",
      "   第 5 页... -> 保存 9 条 (去重 0 条)\n",
      "   第 6 页... -> 保存 1 条 (去重 0 条)\n",
      "   无下一页。\n",
      "\n",
      ">>> 正在抓取: 2025-08-01 至 2025-08-31 <<<\n",
      "   第 1 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 2 页... -> 保存 9 条 (去重 0 条)\n",
      "   第 3 页... -> 保存 9 条 (去重 0 条)\n",
      "   第 4 页... -> 保存 8 条 (去重 0 条)\n",
      "   第 5 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 6 页... -> 保存 9 条 (去重 0 条)\n",
      "   第 7 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 8 页... -> 保存 9 条 (去重 0 条)\n",
      "   第 9 页... -> 保存 6 条 (去重 0 条)\n",
      "   无下一页。\n",
      "\n",
      ">>> 正在抓取: 2025-07-01 至 2025-07-31 <<<\n",
      "   第 1 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 2 页... -> 保存 9 条 (去重 0 条)\n",
      "   第 3 页... -> 保存 9 条 (去重 1 条)\n",
      "   第 4 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 5 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 6 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 7 页... -> 保存 10 条 (去重 0 条)\n",
      "   第 8 页... -> 保存 9 条 (去重 0 条)\n",
      "   第 9 页... -> 保存 10 条 (去重 0 条)\n",
      "   无下一页。\n"
     ]
    }
   ],
   "source": [
    "############# Molly ##########\n",
    "import time\n",
    "import csv\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import datetime\n",
    "import urllib.parse\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# --- 1. 配置区 ---\n",
    "\n",
    "RAW_KEYWORD = \"#Molly#\" \n",
    "CSV_FILE = 'weibo_Molly_Specific_2025.csv'\n",
    "\n",
    "START_DATE = \"2025-07-01\"\n",
    "END_DATE = \"2025-11-26\" \n",
    "\n",
    "MAX_PAGE_PER_MONTH = 50\n",
    "DEFAULT_YEAR = \"2025\"\n",
    "\n",
    "# --- 2. 核心工具函数 ---\n",
    "\n",
    "def get_date_ranges(start, end):\n",
    "    start_date = datetime.datetime.strptime(start, \"%Y-%m-%d\")\n",
    "    end_date = datetime.datetime.strptime(end, \"%Y-%m-%d\")\n",
    "    ranges = []\n",
    "    current = start_date\n",
    "    while current <= end_date:\n",
    "        if current.month == 12:\n",
    "            next_month = current.replace(year=current.year+1, month=1, day=1)\n",
    "        else:\n",
    "            next_month = current.replace(month=current.month+1, day=1)\n",
    "        month_end = next_month - datetime.timedelta(days=1)\n",
    "        if month_end > end_date: month_end = end_date\n",
    "        if current <= month_end:\n",
    "            ranges.append((current.strftime(\"%Y-%m-%d\"), month_end.strftime(\"%Y-%m-%d\")))\n",
    "        current = next_month\n",
    "    return ranges[::-1] \n",
    "\n",
    "def extract_number(text):\n",
    "    match = re.search(r'\\d+', text)\n",
    "    return int(match.group(0)) if match else 0\n",
    "\n",
    "def process_time_regex(raw_text):\n",
    "    if not raw_text: return \"\", \"\", \"\"\n",
    "    text = re.sub(r'\\s+', ' ', raw_text).strip()\n",
    "    now = datetime.datetime.now()\n",
    "    match_full = re.search(r'(\\d{4})年(\\d{1,2})月(\\d{1,2})日\\s*(\\d{1,2}:\\d{2})', text)\n",
    "    if match_full: return match_full.group(1), f\"{match_full.group(2)}月{match_full.group(3)}日\", match_full.group(4)\n",
    "    match_no_year = re.search(r'(\\d{1,2})月(\\d{1,2})日\\s*(\\d{1,2}:\\d{2})', text)\n",
    "    if match_no_year: return DEFAULT_YEAR, f\"{match_no_year.group(1)}月{match_no_year.group(2)}日\", match_no_year.group(3)\n",
    "    match_today = re.search(r'今天\\s*(\\d{1,2}:\\d{2})', text)\n",
    "    if match_today: return str(now.year), f\"{now.month}月{now.day}日\", match_today.group(1)\n",
    "    if \"分\" in text or \"秒\" in text or \"刚刚\" in text: return str(now.year), f\"{now.month}月{now.day}日\", now.strftime(\"%H:%M\")\n",
    "    match_date_only = re.search(r'(\\d{1,2})月(\\d{1,2})日', text)\n",
    "    if match_date_only: return DEFAULT_YEAR, f\"{match_date_only.group(1)}月{match_date_only.group(2)}日\", \"00:00\"\n",
    "    return \"\", text, \"\" \n",
    "\n",
    "def simulate_human_scroll(driver):\n",
    "    \"\"\"模拟下滑加载\"\"\"\n",
    "    # 必须先滑到底，因为微博是懒加载，不滑到底下面的帖子HTML元素都不存在\n",
    "    try:\n",
    "        driver.execute_script(\"window.stop();\") \n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        current_position = 0\n",
    "        while current_position < last_height:\n",
    "            step = random.randint(500, 800)\n",
    "            current_position += step\n",
    "            driver.execute_script(f\"window.scrollTo(0, {current_position});\")\n",
    "            time.sleep(random.uniform(0.2, 0.4))\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if current_position > new_height: break\n",
    "            last_height = new_height\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(1.0)\n",
    "    except: pass\n",
    "\n",
    "def save_to_csv(data, filename):\n",
    "    file_exists = os.path.isfile(filename)\n",
    "    try:\n",
    "        with open(filename, 'a', newline='', encoding='utf-8-sig') as f:\n",
    "            fieldnames = ['用户名', '帖子内容', '发布年份', '发布日期', '发布时间', '转发数', '评论数', '点赞数', '抓取时段']\n",
    "            writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "            if not file_exists: writer.writeheader()\n",
    "            writer.writerows(data)\n",
    "    except Exception as e:\n",
    "        print(f\"写入CSV失败: {e}\")\n",
    "\n",
    "# --- 3. 浏览器配置 ---\n",
    "\n",
    "def get_stealth_driver():\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--start-maximized\")\n",
    "    chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "    chrome_options.add_experimental_option(\"detach\", True)\n",
    "    chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\")\n",
    "\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.set_page_load_timeout(15)\n",
    "    driver.set_script_timeout(15)\n",
    "\n",
    "    driver.execute_cdp_cmd(\"Page.addScriptToEvaluateOnNewDocument\", {\n",
    "        \"source\": \"\"\"\n",
    "            Object.defineProperty(navigator, 'webdriver', { get: () => undefined });\n",
    "            Object.defineProperty(navigator, 'plugins', { get: () => [1, 2, 3, 4, 5] });\n",
    "            Object.defineProperty(navigator, 'languages', { get: () => ['zh-CN', 'zh', 'en'] });\n",
    "        \"\"\"\n",
    "    })\n",
    "    return driver\n",
    "\n",
    "# --- 4. 主程序 ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(f\"正在启动 (目标: {START_DATE} ~ {END_DATE})...\")\n",
    "    \n",
    "    try:\n",
    "        driver = get_stealth_driver()\n",
    "    except Exception as e:\n",
    "        print(\"\\n启动失败，请升级Selenium\")\n",
    "        exit()\n",
    "\n",
    "    seen_posts = set()\n",
    "\n",
    "    try:\n",
    "        driver.get(\"https://weibo.com/\")\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"【请手动扫码登录】\")\n",
    "        print(\"登录成功看到首页后，回到这里按 Enter 键。\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "        input(\"准备好后，请按 Enter 键...\")\n",
    "\n",
    "        print(\"已跳过热身，直接开始...\")\n",
    "\n",
    "        date_ranges = get_date_ranges(START_DATE, END_DATE)\n",
    "        print(f\"任务计划：{len(date_ranges)} 个时段。\")\n",
    "\n",
    "        for start_t, end_t in date_ranges:\n",
    "            encoded_keyword = urllib.parse.quote(RAW_KEYWORD)\n",
    "            search_url = f\"https://s.weibo.com/weibo?q={encoded_keyword}&typeall=1&suball=1&timescope=custom:{start_t}:{end_t}&Refer=g&nodup=1\"\n",
    "            \n",
    "            print(f\"\\n>>> 正在抓取: {start_t} 至 {end_t} <<<\")\n",
    "            \n",
    "            try:\n",
    "                driver.get(search_url)\n",
    "                time.sleep(random.uniform(3, 5))\n",
    "            except TimeoutException:\n",
    "                print(\"   页面加载超时(>15s)，强制停止加载并开始解析...\")\n",
    "                driver.execute_script(\"window.stop();\") \n",
    "\n",
    "            if \"抱歉，未找到\" in driver.page_source:\n",
    "                print(f\"   微博提示：未找到相关结果。\")\n",
    "                continue\n",
    "\n",
    "            page_count = 1\n",
    "            while True:\n",
    "                print(f\"   第 {page_count} 页...\", end=\"\")\n",
    "                \n",
    "                try:\n",
    "                    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div.card-wrap\")))\n",
    "                except:\n",
    "                    print(\" -> 等待超时\")\n",
    "\n",
    "                # 必须先下滑，确保帖子加载出来，否则 find_elements 找不到\n",
    "                simulate_human_scroll(driver)\n",
    "\n",
    "                page_data = []\n",
    "                # 获取本页所有帖子元素\n",
    "                posts = driver.find_elements(By.CSS_SELECTOR, \"div.card-wrap\")\n",
    "                duplicate_count = 0\n",
    "                \n",
    "                # --- 针对每条帖子单独处理 ---\n",
    "                for post in posts:\n",
    "                    try:\n",
    "                        if \"card-no-result\" in post.get_attribute(\"class\"): continue\n",
    "                        \n",
    "                        # 1. 【关键修改】在处理当前帖子前，先检查并点击它内部的展开按钮\n",
    "                        try:\n",
    "                            # 使用相对 XPath (.//) 查找当前 post 内部的展开按钮\n",
    "                            expand_btn = post.find_element(By.XPATH, './/a[@action-type=\"fl_unfold\"]')\n",
    "                            driver.execute_script(\"arguments[0].click();\", expand_btn)\n",
    "                            time.sleep(0.1) # 稍等一下，让内容展开\n",
    "                        except:\n",
    "                            # 如果没有展开按钮，或者报错，说明不需要展开，直接继续\n",
    "                            pass\n",
    "\n",
    "                        # 2. 开始抓取信息\n",
    "                        try:\n",
    "                            user_name = post.find_element(By.CSS_SELECTOR, 'p.txt').get_attribute('nick-name')\n",
    "                        except: continue\n",
    "                        \n",
    "                        content = \"\"\n",
    "                        try:\n",
    "                            content = post.find_element(By.CSS_SELECTOR, 'p[node-type=\"feed_list_content\"]').get_attribute('textContent').replace('收起', '').replace('展开', '').strip()\n",
    "                        except: pass\n",
    "                        if not content: content = \"[内容提取失败]\"\n",
    "\n",
    "                        year, date_part, time_part = \"\", \"\", \"\"\n",
    "                        try:\n",
    "                            time_element = post.find_element(By.CSS_SELECTOR, 'a[suda-data*=\"click:wb_time\"]')\n",
    "                            year, date_part, time_part = process_time_regex(time_element.get_attribute('textContent'))\n",
    "                        except:\n",
    "                            try:\n",
    "                                links = post.find_element(By.CSS_SELECTOR, 'p.from').find_elements(By.TAG_NAME, 'a')\n",
    "                                for link in links:\n",
    "                                    if \"月\" in link.text or \"今天\" in link.text:\n",
    "                                        year, date_part, time_part = process_time_regex(link.text)\n",
    "                                        break\n",
    "                            except: pass\n",
    "\n",
    "                        unique_id = f\"{user_name}_{content[:30]}_{date_part}_{time_part}\"\n",
    "                        if unique_id in seen_posts:\n",
    "                            duplicate_count += 1\n",
    "                            continue \n",
    "                        seen_posts.add(unique_id)\n",
    "\n",
    "                        forwards = comments = likes = 0\n",
    "                        try:\n",
    "                            acts = post.find_elements(By.CSS_SELECTOR, 'div.card-act > ul > li')\n",
    "                            if len(acts) >= 3:\n",
    "                                forwards = extract_number(acts[0].text)\n",
    "                                comments = extract_number(acts[1].text)\n",
    "                                likes = extract_number(acts[2].text)\n",
    "                        except: pass\n",
    "\n",
    "                        page_data.append({\n",
    "                            '用户名': user_name, '帖子内容': content, \n",
    "                            '发布年份': year, '发布日期': date_part, '发布时间': time_part,\n",
    "                            '转发数': forwards, '评论数': comments, '点赞数': likes,\n",
    "                            '抓取时段': f\"{start_t}_{end_t}\"\n",
    "                        })\n",
    "\n",
    "                    except: continue\n",
    "\n",
    "                if page_data:\n",
    "                    save_to_csv(page_data, CSV_FILE)\n",
    "                    print(f\" -> 保存 {len(page_data)} 条 (去重 {duplicate_count} 条)\")\n",
    "                else:\n",
    "                    print(f\" -> 本页无新数据\")\n",
    "\n",
    "                if page_count >= MAX_PAGE_PER_MONTH:\n",
    "                    print(\"   月度翻页上限，切换下月。\")\n",
    "                    break\n",
    "\n",
    "                try:\n",
    "                    next_btn = driver.find_element(By.CSS_SELECTOR, 'a.next')\n",
    "                    time.sleep(random.uniform(3, 5))\n",
    "                    next_btn.click()\n",
    "                    page_count += 1\n",
    "                    time.sleep(random.uniform(3, 5))\n",
    "                except:\n",
    "                    print(\"   无下一页。\")\n",
    "                    break\n",
    "            \n",
    "            time.sleep(random.uniform(3, 5))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"程序异常: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ac3c087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在启动隐身模式浏览器 (Skullpanda 2025版)...\n",
      "\n",
      "============================================================\n",
      "【请手动扫码登录】\n",
      "1. 请使用手机微博APP扫码。\n",
      "2. 登录成功并看到微博首页后，回到这里按 Enter 键。\n",
      "============================================================\n",
      "\n",
      "正在进行热身搜索...\n",
      "热身完成，开始抓取 2025 年数据。\n",
      "任务计划：分为 11 个月度时段。\n",
      "\n",
      ">>> 正在抓取时段: 2025-11-01 至 2025-11-26 <<<\n",
      "   第 1 页...\n",
      "   保存 10 条。\n",
      "   第 2 页...\n",
      "   保存 10 条。\n",
      "   第 3 页...\n",
      "   保存 10 条。\n",
      "   第 4 页...\n",
      "   保存 10 条。\n",
      "   第 5 页...\n",
      "   保存 8 条。\n",
      "   第 6 页...\n",
      "   保存 10 条。\n",
      "   第 7 页...\n",
      "   保存 10 条。\n",
      "   第 8 页...\n",
      "   保存 10 条。\n",
      "   第 9 页...\n",
      "   保存 9 条。\n",
      "   第 10 页...\n",
      "   保存 10 条。\n",
      "   第 11 页...\n",
      "   保存 3 条。\n",
      "   无下一页。\n",
      "\n",
      ">>> 正在抓取时段: 2025-10-01 至 2025-10-31 <<<\n",
      "   第 1 页...\n",
      "   保存 10 条。\n",
      "   第 2 页...\n",
      "   保存 10 条。\n",
      "   第 3 页...\n",
      "   保存 10 条。\n",
      "   第 4 页...\n",
      "   保存 10 条。\n",
      "   第 5 页...\n",
      "   保存 10 条。\n",
      "   第 6 页...\n",
      "   保存 9 条。\n",
      "   无下一页。\n",
      "\n",
      ">>> 正在抓取时段: 2025-09-01 至 2025-09-30 <<<\n",
      "   第 1 页...\n",
      "   保存 10 条。\n",
      "   第 2 页...\n",
      "   保存 9 条。\n",
      "   第 3 页...\n",
      "   保存 10 条。\n",
      "   第 4 页...\n",
      "   保存 10 条。\n",
      "   第 5 页...\n",
      "   保存 10 条。\n",
      "   第 6 页...\n",
      "   保存 10 条。\n",
      "   第 7 页...\n",
      "   保存 10 条。\n",
      "   第 8 页...\n",
      "   保存 10 条。\n",
      "   第 9 页...\n",
      "   保存 10 条。\n",
      "   第 10 页...\n",
      "   保存 10 条。\n",
      "   第 11 页...\n",
      "   保存 10 条。\n",
      "   第 12 页...\n",
      "   保存 10 条。\n",
      "   第 13 页...\n",
      "   保存 10 条。\n",
      "   第 14 页...\n",
      "   保存 10 条。\n",
      "   第 15 页...\n",
      "   保存 9 条。\n",
      "   第 16 页...\n",
      "   保存 10 条。\n",
      "   第 17 页...\n",
      "   保存 9 条。\n",
      "   第 18 页...\n",
      "   保存 1 条。\n",
      "   无下一页。\n",
      "\n",
      ">>> 正在抓取时段: 2025-08-01 至 2025-08-31 <<<\n",
      "   第 1 页...\n",
      "   保存 10 条。\n",
      "   第 2 页...\n",
      "   保存 8 条。\n",
      "   第 3 页...\n",
      "   保存 9 条。\n",
      "   第 4 页...\n",
      "   保存 10 条。\n",
      "   第 5 页...\n",
      "   保存 9 条。\n",
      "   第 6 页...\n",
      "   保存 10 条。\n",
      "   第 7 页...\n",
      "   保存 10 条。\n",
      "   第 8 页...\n",
      "   保存 9 条。\n",
      "   第 9 页...\n",
      "   保存 8 条。\n",
      "   第 10 页...\n",
      "   保存 9 条。\n",
      "   第 11 页...\n",
      "   保存 9 条。\n",
      "   第 12 页...\n",
      "   保存 9 条。\n",
      "   第 13 页...\n",
      "   保存 10 条。\n",
      "   第 14 页...\n",
      "   保存 6 条。\n",
      "   无下一页。\n",
      "\n",
      ">>> 正在抓取时段: 2025-07-01 至 2025-07-31 <<<\n",
      "   第 1 页...\n",
      "   保存 9 条。\n",
      "   第 2 页...\n",
      "   保存 10 条。\n",
      "   第 3 页...\n",
      "   保存 10 条。\n",
      "   第 4 页...\n",
      "   保存 9 条。\n",
      "   第 5 页...\n",
      "   保存 7 条。\n",
      "   第 6 页...\n",
      "   保存 8 条。\n",
      "   第 7 页...\n",
      "   保存 10 条。\n",
      "   第 8 页...\n",
      "   保存 10 条。\n",
      "   第 9 页...\n",
      "   保存 9 条。\n",
      "   第 10 页...\n",
      "   保存 10 条。\n",
      "   第 11 页...\n",
      "   保存 8 条。\n",
      "   第 12 页...\n",
      "   保存 9 条。\n",
      "   第 13 页...\n",
      "   保存 7 条。\n",
      "   无下一页。\n",
      "\n",
      ">>> 正在抓取时段: 2025-06-01 至 2025-06-30 <<<\n",
      "   第 1 页...\n",
      "   保存 9 条。\n",
      "   第 2 页...\n",
      "   保存 8 条。\n",
      "   第 3 页...\n",
      "   保存 9 条。\n",
      "   第 4 页...\n",
      "   保存 10 条。\n",
      "   第 5 页...\n",
      "   保存 10 条。\n",
      "   第 6 页...\n",
      "   保存 9 条。\n",
      "   第 7 页...\n",
      "   保存 9 条。\n",
      "   第 8 页...\n",
      "   保存 10 条。\n",
      "   第 9 页...\n",
      "   保存 9 条。\n",
      "   第 10 页...\n",
      "   保存 9 条。\n",
      "   第 11 页...\n",
      "   保存 10 条。\n",
      "   第 12 页...\n",
      "   保存 9 条。\n",
      "   第 13 页...\n",
      "   保存 10 条。\n",
      "   第 14 页...\n",
      "   保存 10 条。\n",
      "   第 15 页...\n",
      "   保存 9 条。\n",
      "   第 16 页...\n",
      "   保存 8 条。\n",
      "   第 17 页...\n",
      "   保存 10 条。\n",
      "   第 18 页...\n",
      "   保存 10 条。\n",
      "   第 19 页...\n",
      "   保存 10 条。\n",
      "   第 20 页...\n",
      "   保存 8 条。\n",
      "   第 21 页...\n",
      "   保存 9 条。\n",
      "   第 22 页...\n",
      "   保存 9 条。\n",
      "   第 23 页...\n",
      "   保存 8 条。\n",
      "   第 24 页...\n",
      "   保存 10 条。\n",
      "   第 25 页...\n",
      "   保存 8 条。\n",
      "   第 26 页...\n",
      "   保存 10 条。\n",
      "   第 27 页...\n",
      "   保存 9 条。\n",
      "   第 28 页...\n",
      "   保存 6 条。\n",
      "   第 29 页...\n",
      "   保存 10 条。\n",
      "   第 30 页...\n",
      "   保存 10 条。\n",
      "   第 31 页...\n",
      "   保存 10 条。\n",
      "   第 32 页...\n",
      "   保存 10 条。\n",
      "   第 33 页...\n",
      "   保存 10 条。\n",
      "   第 34 页...\n",
      "   保存 5 条。\n",
      "   无下一页。\n",
      "\n",
      ">>> 正在抓取时段: 2025-05-01 至 2025-05-31 <<<\n",
      "   第 1 页...\n",
      "   保存 9 条。\n",
      "   第 2 页...\n",
      "   保存 8 条。\n",
      "   第 3 页...\n",
      "   保存 10 条。\n",
      "   第 4 页...\n",
      "   保存 7 条。\n",
      "   无下一页。\n",
      "\n",
      ">>> 正在抓取时段: 2025-04-01 至 2025-04-30 <<<\n",
      "   第 1 页...\n",
      "   保存 8 条。\n",
      "   第 2 页...\n",
      "   保存 10 条。\n",
      "   第 3 页...\n",
      "   保存 10 条。\n",
      "   第 4 页...\n",
      "   保存 6 条。\n",
      "   第 5 页...\n",
      "   保存 9 条。\n",
      "   第 6 页...\n",
      "   保存 8 条。\n",
      "   第 7 页...\n",
      "   保存 6 条。\n",
      "   无下一页。\n",
      "\n",
      ">>> 正在抓取时段: 2025-03-01 至 2025-03-31 <<<\n",
      "   第 1 页...\n",
      "   保存 8 条。\n",
      "   第 2 页...\n",
      "   保存 9 条。\n",
      "   第 3 页...\n",
      "   保存 6 条。\n",
      "   第 4 页...\n",
      "   保存 8 条。\n",
      "   第 5 页...\n",
      "   保存 8 条。\n",
      "   第 6 页...\n",
      "   保存 8 条。\n",
      "   第 7 页...\n",
      "   保存 5 条。\n",
      "   无下一页。\n",
      "\n",
      ">>> 正在抓取时段: 2025-02-01 至 2025-02-28 <<<\n",
      "   第 1 页...\n",
      "   保存 9 条。\n",
      "   第 2 页...\n",
      "   保存 7 条。\n",
      "   第 3 页...\n",
      "   保存 4 条。\n",
      "   无下一页。\n",
      "\n",
      ">>> 正在抓取时段: 2025-01-01 至 2025-01-31 <<<\n",
      "   第 1 页...\n",
      "   保存 9 条。\n",
      "   第 2 页...\n",
      "   保存 8 条。\n",
      "   无下一页。\n"
     ]
    }
   ],
   "source": [
    "############## Skullpanda ############\n",
    "import time\n",
    "import csv\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import datetime\n",
    "import urllib.parse\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# --- 1. 配置区 (已更新为 Skullpanda) ---\n",
    "\n",
    "# 关键词\n",
    "RAW_KEYWORD = \"#skullpanda#\" \n",
    "# 文件名\n",
    "CSV_FILE = 'weibo_Skullpanda_2025_Full.csv'\n",
    "\n",
    "# 时间范围：2025 全年\n",
    "START_DATE = \"2025-01-01\"\n",
    "END_DATE = \"2025-12-31\" \n",
    "\n",
    "MAX_PAGE_PER_MONTH = 50\n",
    "DEFAULT_YEAR = \"2025\"\n",
    "\n",
    "# --- 2. 核心工具函数 ---\n",
    "\n",
    "def get_date_ranges(start, end):\n",
    "    start_date = datetime.datetime.strptime(start, \"%Y-%m-%d\")\n",
    "    end_date = datetime.datetime.strptime(end, \"%Y-%m-%d\")\n",
    "    now = datetime.datetime.now()\n",
    "    if end_date > now: end_date = now\n",
    "    ranges = []\n",
    "    current = start_date\n",
    "    while current <= end_date:\n",
    "        if current.month == 12:\n",
    "            next_month = current.replace(year=current.year+1, month=1, day=1)\n",
    "        else:\n",
    "            next_month = current.replace(month=current.month+1, day=1)\n",
    "        month_end = next_month - datetime.timedelta(days=1)\n",
    "        if month_end > end_date: month_end = end_date\n",
    "        if current <= month_end:\n",
    "            ranges.append((current.strftime(\"%Y-%m-%d\"), month_end.strftime(\"%Y-%m-%d\")))\n",
    "        current = next_month\n",
    "    # 倒序：从最近的月份开始爬\n",
    "    return ranges[::-1] \n",
    "\n",
    "def extract_number(text):\n",
    "    match = re.search(r'\\d+', text)\n",
    "    return int(match.group(0)) if match else 0\n",
    "\n",
    "def process_time_regex(raw_text):\n",
    "    if not raw_text: return \"\", \"\", \"\"\n",
    "    text = re.sub(r'\\s+', ' ', raw_text).strip()\n",
    "    now = datetime.datetime.now()\n",
    "    match_full = re.search(r'(\\d{4})年(\\d{1,2})月(\\d{1,2})日\\s*(\\d{1,2}:\\d{2})', text)\n",
    "    if match_full: return match_full.group(1), f\"{match_full.group(2)}月{match_full.group(3)}日\", match_full.group(4)\n",
    "    match_no_year = re.search(r'(\\d{1,2})月(\\d{1,2})日\\s*(\\d{1,2}:\\d{2})', text)\n",
    "    if match_no_year: return DEFAULT_YEAR, f\"{match_no_year.group(1)}月{match_no_year.group(2)}日\", match_no_year.group(3)\n",
    "    match_today = re.search(r'今天\\s*(\\d{1,2}:\\d{2})', text)\n",
    "    if match_today: return str(now.year), f\"{now.month}月{now.day}日\", match_today.group(1)\n",
    "    if \"分\" in text or \"秒\" in text or \"刚刚\" in text: return str(now.year), f\"{now.month}月{now.day}日\", now.strftime(\"%H:%M\")\n",
    "    match_date_only = re.search(r'(\\d{1,2})月(\\d{1,2})日', text)\n",
    "    if match_date_only: return DEFAULT_YEAR, f\"{match_date_only.group(1)}月{match_date_only.group(2)}日\", \"00:00\"\n",
    "    return \"\", text, \"\" \n",
    "\n",
    "def simulate_human_scroll(driver):\n",
    "    try:\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        current_position = 0\n",
    "        while current_position < last_height:\n",
    "            step = random.randint(500, 800)\n",
    "            current_position += step\n",
    "            driver.execute_script(f\"window.scrollTo(0, {current_position});\")\n",
    "            time.sleep(random.uniform(0.3, 0.6))\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if current_position > new_height: break\n",
    "            last_height = new_height\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(1.5)\n",
    "    except: pass\n",
    "\n",
    "def save_to_csv(data, filename):\n",
    "    file_exists = os.path.isfile(filename)\n",
    "    try:\n",
    "        with open(filename, 'a', newline='', encoding='utf-8-sig') as f:\n",
    "            fieldnames = ['用户名', '帖子内容', '发布年份', '发布日期', '发布时间', '转发数', '评论数', '点赞数', '抓取时段']\n",
    "            writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "            if not file_exists: writer.writeheader()\n",
    "            writer.writerows(data)\n",
    "    except Exception as e:\n",
    "        print(f\"写入CSV失败: {e}\")\n",
    "\n",
    "# --- 3. CDP 隐身浏览器配置 ---\n",
    "\n",
    "def get_stealth_driver():\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--start-maximized\")\n",
    "    chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "    chrome_options.add_experimental_option(\"detach\", True)\n",
    "    chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\")\n",
    "\n",
    "    # 使用原生驱动管理，避免路径报错\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "    driver.execute_cdp_cmd(\"Page.addScriptToEvaluateOnNewDocument\", {\n",
    "        \"source\": \"\"\"\n",
    "            Object.defineProperty(navigator, 'webdriver', { get: () => undefined });\n",
    "            Object.defineProperty(navigator, 'plugins', { get: () => [1, 2, 3, 4, 5] });\n",
    "            Object.defineProperty(navigator, 'languages', { get: () => ['zh-CN', 'zh', 'en'] });\n",
    "            const getParameter = WebGLRenderingContext.prototype.getParameter;\n",
    "            WebGLRenderingContext.prototype.getParameter = function(parameter) {\n",
    "                if (parameter === 37445) { return 'Intel Open Source Technology Center'; }\n",
    "                if (parameter === 37446) { return 'Mesa DRI Intel(R) Ivybridge Mobile '; }\n",
    "                return getParameter(parameter);\n",
    "            };\n",
    "        \"\"\"\n",
    "    })\n",
    "    return driver\n",
    "\n",
    "# --- 4. 主程序 ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"正在启动隐身模式浏览器 (Skullpanda 2025版)...\")\n",
    "    \n",
    "    try:\n",
    "        driver = get_stealth_driver()\n",
    "    except Exception as e:\n",
    "        print(\"\\n启动失败！请尝试升级 Selenium: pip install --upgrade selenium\")\n",
    "        print(f\"详细错误: {e}\")\n",
    "        exit()\n",
    "\n",
    "    try:\n",
    "        driver.get(\"https://weibo.com/\")\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"【请手动扫码登录】\")\n",
    "        print(\"1. 请使用手机微博APP扫码。\")\n",
    "        print(\"2. 登录成功并看到微博首页后，回到这里按 Enter 键。\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "        input(\"准备好后，请按 Enter 键...\")\n",
    "\n",
    "        print(\"正在进行热身搜索...\")\n",
    "        encoded_keyword = urllib.parse.quote(RAW_KEYWORD)\n",
    "        driver.get(f\"https://s.weibo.com/weibo?q={encoded_keyword}&Refer=index\")\n",
    "        simulate_human_scroll(driver)\n",
    "        time.sleep(random.uniform(3, 5))\n",
    "        print(\"热身完成，开始抓取 2025 年数据。\")\n",
    "\n",
    "        date_ranges = get_date_ranges(START_DATE, END_DATE)\n",
    "        print(f\"任务计划：分为 {len(date_ranges)} 个月度时段。\")\n",
    "\n",
    "        for start_t, end_t in date_ranges:\n",
    "            search_url = f\"https://s.weibo.com/weibo?q={encoded_keyword}&typeall=1&suball=1&timescope=custom:{start_t}:{end_t}&Refer=g\"\n",
    "            \n",
    "            print(f\"\\n>>> 正在抓取时段: {start_t} 至 {end_t} <<<\")\n",
    "            driver.get(search_url)\n",
    "            time.sleep(random.uniform(4, 6)) \n",
    "\n",
    "            if \"抱歉，未找到\" in driver.page_source:\n",
    "                print(f\"   该时段无内容，跳过。\")\n",
    "                continue\n",
    "\n",
    "            page_count = 1\n",
    "            while True:\n",
    "                print(f\"   第 {page_count} 页...\")\n",
    "                try:\n",
    "                    WebDriverWait(driver, 8).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div.card-wrap\")))\n",
    "                except:\n",
    "                    print(\"   等待超时 (可能无内容)。\")\n",
    "\n",
    "                simulate_human_scroll(driver)\n",
    "\n",
    "                try:\n",
    "                    expand_buttons = driver.find_elements(By.XPATH, '//a[@action-type=\"fl_unfold\"]')\n",
    "                    for btn in expand_buttons:\n",
    "                        driver.execute_script(\"arguments[0].click();\", btn)\n",
    "                        time.sleep(0.2)\n",
    "                except: pass\n",
    "\n",
    "                page_data = []\n",
    "                posts = driver.find_elements(By.CSS_SELECTOR, \"div.card-wrap\")\n",
    "                \n",
    "                for post in posts:\n",
    "                    try:\n",
    "                        if \"card-no-result\" in post.get_attribute(\"class\"): continue\n",
    "                        try:\n",
    "                            user_name = post.find_element(By.CSS_SELECTOR, 'p.txt').get_attribute('nick-name')\n",
    "                        except: continue\n",
    "                        \n",
    "                        content = \"\"\n",
    "                        try:\n",
    "                            content = post.find_element(By.CSS_SELECTOR, 'p[node-type=\"feed_list_content\"]').get_attribute('textContent').replace('收起', '').replace('展开', '').strip()\n",
    "                        except: pass\n",
    "                        if not content: content = \"[内容提取失败或仅图片]\"\n",
    "\n",
    "                        year, date_part, time_part = \"\", \"\", \"\"\n",
    "                        try:\n",
    "                            time_element = post.find_element(By.CSS_SELECTOR, 'a[suda-data*=\"click:wb_time\"]')\n",
    "                            year, date_part, time_part = process_time_regex(time_element.get_attribute('textContent'))\n",
    "                        except:\n",
    "                            try:\n",
    "                                links = post.find_element(By.CSS_SELECTOR, 'p.from').find_elements(By.TAG_NAME, 'a')\n",
    "                                for link in links:\n",
    "                                    if \"月\" in link.text or \"今天\" in link.text:\n",
    "                                        year, date_part, time_part = process_time_regex(link.text)\n",
    "                                        break\n",
    "                            except: pass\n",
    "\n",
    "                        forwards = comments = likes = 0\n",
    "                        try:\n",
    "                            acts = post.find_elements(By.CSS_SELECTOR, 'div.card-act > ul > li')\n",
    "                            if len(acts) >= 3:\n",
    "                                forwards = extract_number(acts[0].text)\n",
    "                                comments = extract_number(acts[1].text)\n",
    "                                likes = extract_number(acts[2].text)\n",
    "                        except: pass\n",
    "\n",
    "                        page_data.append({\n",
    "                            '用户名': user_name, '帖子内容': content, \n",
    "                            '发布年份': year, '发布日期': date_part, '发布时间': time_part,\n",
    "                            '转发数': forwards, '评论数': comments, '点赞数': likes,\n",
    "                            '抓取时段': f\"{start_t}_{end_t}\"\n",
    "                        })\n",
    "                    except: continue\n",
    "\n",
    "                if page_data:\n",
    "                    save_to_csv(page_data, CSV_FILE)\n",
    "                    print(f\"   保存 {len(page_data)} 条。\")\n",
    "                else:\n",
    "                    print(\"   本页未提取到有效数据。\")\n",
    "\n",
    "                if page_count >= MAX_PAGE_PER_MONTH:\n",
    "                    print(\"   达到单月页数上限，切换下一月。\")\n",
    "                    break\n",
    "\n",
    "                try:\n",
    "                    next_btn = driver.find_element(By.CSS_SELECTOR, 'a.next')\n",
    "                    time.sleep(random.uniform(3, 5))\n",
    "                    next_btn.click()\n",
    "                    page_count += 1\n",
    "                    time.sleep(random.uniform(3, 5))\n",
    "                except:\n",
    "                    print(\"   无下一页。\")\n",
    "                    break\n",
    "            \n",
    "            time.sleep(random.uniform(4, 6))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"程序异常: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
